# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# Cloud LLM API (required for Render deployment)
# Get Groq API key: https://console.groq.com/ (free tier)
GROQ_API_KEY=your_groq_api_key_here

# HuggingFace Embeddings API (required for Render deployment)
# Get token: https://huggingface.co/settings/tokens
HUGGINGFACEHUB_API_TOKEN=your_hf_token_here

# Vector Database
CHROMA_PERSIST_DIR=./data/chroma

# Redis (optional for caching - strongly recommended for production)
REDIS_URL=redis://localhost:6379
REDIS_MAX_CONNECTIONS=10

# Performance & Caching
CACHE_TTL=3600
MAX_FILE_SIZE_MB=10
